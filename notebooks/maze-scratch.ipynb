{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/Code/miniconda3/envs/interp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/eric/Code/miniconda3/envs/interp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/eric/Code/miniconda3/envs/interp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/eric/Code/miniconda3/envs/interp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/eric/Code/miniconda3/envs/interp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/eric/Code/miniconda3/envs/interp/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import imageio\n",
    "from IPython.display import Image\n",
    "\n",
    "import mazelab\n",
    "from mazelab.generators import random_maze\n",
    "from mazelab.env import RandomizingMazeEnv\n",
    "\n",
    "import gym\n",
    "from gym.spaces import Box\n",
    "from gym.spaces import Discrete\n",
    "\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
    "from stable_baselines3 import A2C, DQN, PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = RandomizingMazeEnv(\n",
    "    width=7,\n",
    "    height=7,\n",
    "    randomize_start=False,\n",
    "    randomize_goal=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5aeb785d50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = RandomizingMazeEnv(\n",
    "    width=8,\n",
    "    height=8,\n",
    "    randomize_start=True,\n",
    "    randomize_goal=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5aeb748410>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('RandomMaze-8x8-FixedGoal-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5aeae9be90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(env.reset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020-09-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage\n",
    "import skimage.transform\n",
    "\n",
    "import gym\n",
    "import mazelab\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import imageio\n",
    "from IPython.display import Image\n",
    "\n",
    "from stable_baselines3 import A2C\n",
    "sys.path.insert(1, \"../rl-baselines3-zoo\")\n",
    "import utils.import_envs  # noqa: F401 pylint: disable=unused-import\n",
    "from utils.utils import StoreDict\n",
    "from utils import ALGOS, create_test_env, get_latest_run_id, get_saved_hyperparams\n",
    "\n",
    "from interp.common.wrappers import CustomRewardSSWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "########### Set Device ############\n",
    "# device = th.device('cuda' if th.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "dtype = th.float32\n",
    "th.set_default_dtype(dtype)\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardModel(nn.Module):\n",
    "    \"\"\"A reward model using an A2C feature extractor\"\"\"\n",
    "    def __init__(self, env, device):\n",
    "        super(RewardModel, self).__init__()\n",
    "        w, h = env.observation_space.shape\n",
    "        features = 2 * w * h\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(features, 64, bias=True),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 64, bias=True),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 1, bias=False),\n",
    "        ).to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, obs):\n",
    "#         print(type(obs))\n",
    "        x = th.tensor(obs).to(dtype).to(self.device)\n",
    "#         print(x.shape, x.dtype)\n",
    "#         x = x.reshape((1, 2, 11, 11))\n",
    "#         print(x)\n",
    "        return self.net(x)\n",
    "    \n",
    "    def tforward(self, ss):\n",
    "        return self.net(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = [\n",
    "    \"EmptyMaze-10x10-FixedGoal-v3\",\n",
    "    \"EmptyMaze-10x10-CoinFlipGoal-v3\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmptyMaze-10x10-FixedGoal-v3\n"
     ]
    }
   ],
   "source": [
    "env_id = envs[0]\n",
    "print(env_id)\n",
    "folder = \"../agents\"\n",
    "algo = \"ppo\"\n",
    "n_timesteps = 10000\n",
    "num_threads = -1\n",
    "n_envs = 1\n",
    "exp_id = 1\n",
    "verbose = 1\n",
    "no_render = False\n",
    "deterministic = False\n",
    "load_best = True\n",
    "load_checkpoint = None\n",
    "norm_reward = False\n",
    "seed = 0\n",
    "reward_log = ''\n",
    "env_kwargs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "if exp_id > 0:\n",
    "    log_path = os.path.join(folder, algo, '{}_{}'.format(env_id, exp_id))\n",
    "else:\n",
    "    log_path = os.path.join(folder, algo)\n",
    "    \n",
    "found = False\n",
    "for ext in ['zip']:\n",
    "    model_path = os.path.join(log_path, f'{env_id}.{ext}')\n",
    "    found = os.path.isfile(model_path)\n",
    "    if found:\n",
    "        break\n",
    "\n",
    "if load_best:\n",
    "    model_path = os.path.join(log_path, \"best_model.zip\")\n",
    "    found = os.path.isfile(model_path)\n",
    "\n",
    "if load_checkpoint is not None:\n",
    "    model_path = os.path.join(log_path, f\"rl_model_{load_checkpoint}_steps.zip\")\n",
    "    found = os.path.isfile(model_path)\n",
    "\n",
    "if not found:\n",
    "    raise ValueError(f\"No model found for {algo} on {env_id}, path: {model_path}\")\n",
    "\n",
    "if algo in ['dqn', 'ddpg', 'sac', 'td3']:\n",
    "    n_envs = 1\n",
    "\n",
    "\n",
    "if num_threads > 0:\n",
    "    if verbose > 1:\n",
    "        print(f\"Setting torch.num_threads to {num_threads}\")\n",
    "    th.set_num_threads(num_threads)\n",
    "\n",
    "is_atari = 'NoFrameskip' in env_id\n",
    "\n",
    "stats_path = os.path.join(log_path, env_id)\n",
    "hyperparams, stats_path = get_saved_hyperparams(stats_path, norm_reward=norm_reward, test_mode=True)\n",
    "env_kwargs = {} if env_kwargs is None else env_kwargs\n",
    "\n",
    "log_dir = reward_log if reward_log != '' else None\n",
    "\n",
    "# env = create_test_env(env_id, n_envs=n_envs,\n",
    "#                       stats_path=stats_path, seed=seed, log_dir=log_dir,\n",
    "#                       should_render=not no_render,\n",
    "#                       hyperparams=hyperparams,\n",
    "#                       env_kwargs=env_kwargs)\n",
    "\n",
    "env = gym.make(env_id)\n",
    "model = ALGOS[algo].load(model_path, env=env, device=device)\n",
    "\n",
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/gif": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "image/gif": {
       "height": 110,
       "width": 110
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = []\n",
    "for n in range(30):\n",
    "    obs = env.reset()\n",
    "    for _ in range(1000):\n",
    "        action, _states = model.predict(obs, deterministic=False)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            break\n",
    "        frame = env.get_image()\n",
    "        images.append(frame)\n",
    "\n",
    "imageio.mimsave(f'tmp/PPO-EmptyMaze-v2-rollout.gif', images, fps=29)\n",
    "Image(filename=f\"tmp/PPO-EmptyMaze-v2-rollout.gif\", width=110, height=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm = RewardModel(env, 'cpu').to('cpu')\n",
    "rm.load_state_dict(th.load(f\"../reward-models/{env_id}_ss-reward_model.pt\", map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: +0.01 +0.00 +0.00 -0.00 +0.01 +0.00 +0.00 +0.01 +0.00 -0.00 +0.01 +0.00 -0.00 -0.01 -0.00 -0.01 +0.01 +0.01 +0.01 +0.01 +0.00 +0.01 +0.01 +0.00 +0.01 +0.01 +0.00 +0.00 +0.01 +0.01 \n",
      "True     : +0.00 +0.00 +0.00 +0.00 +0.00 +0.00 +0.00 +0.00 +0.00 +0.00 +0.00 +0.00 +0.00 +0.00 +0.00 +0.00 +0.00 +0.00 +0.00 +0.00 +0.00 +0.00 +0.00 +0.00 +0.00 +0.00 +0.00 +0.00 +0.00 +0.00 \n"
     ]
    }
   ],
   "source": [
    "N = 30\n",
    "\n",
    "obs = env.reset()\n",
    "next_obs = None\n",
    "predicted_rewards = []\n",
    "true_rewards = []\n",
    "for i in range(N):\n",
    "    action, _states = model.predict(obs, deterministic=False)\n",
    "    next_obs, reward, done, info = env.step(action)\n",
    "    reward_input = np.array((obs, next_obs)).astype(np.float32)\n",
    "    predicted_rewards.append(float(rm(np.expand_dims(reward_input, axis=0)).item()))\n",
    "    true_rewards.append(float(reward))\n",
    "    if done:\n",
    "        break\n",
    "    else:\n",
    "        obs = next_obs\n",
    "print(\"Predicted: \", end='')\n",
    "for i in range(len(predicted_rewards)):\n",
    "    print(\"{:+.2f}\".format(predicted_rewards[i]), end=' ')\n",
    "print(\"\")\n",
    "print(\"True     : \", end='')\n",
    "for i in range(len(predicted_rewards)):\n",
    "    print(\"{:+.2f}\".format(true_rewards[i]), end=' ')\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "senv = CustomRewardSSWrapper(model.env, rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = senv.reset()\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 1 1 1 1 1 1 1 1 1 1]\n",
      "  [1 0 0 0 0 0 0 0 0 0 1]\n",
      "  [1 0 0 0 0 0 0 0 0 0 1]\n",
      "  [1 0 0 0 0 2 0 0 0 0 1]\n",
      "  [1 0 0 0 0 0 0 0 0 0 1]\n",
      "  [1 0 0 0 0 0 0 0 0 0 1]\n",
      "  [1 0 0 0 0 0 0 0 0 0 1]\n",
      "  [1 0 0 0 0 0 0 0 0 0 1]\n",
      "  [1 0 0 0 0 0 0 0 0 0 1]\n",
      "  [1 0 0 0 0 0 0 0 0 3 1]\n",
      "  [1 1 1 1 1 1 1 1 1 1 1]]]\n",
      "[tensor([[1.0043]], grad_fn=<MmBackward>)]\n"
     ]
    }
   ],
   "source": [
    "o, r, _, _ = senv.step([3])\n",
    "print(o)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "next_obs = None\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 2., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 2., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "1.0042983293533325\n"
     ]
    }
   ],
   "source": [
    "next_obs, reward, done, info = env.step(3)\n",
    "reward_input = np.array((obs, next_obs)).astype(np.float32)\n",
    "print(float(rm(np.expand_dims(reward_input, axis=0)).item()))\n",
    "obs = next_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]], dtype=uint8)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = model.env.reset()\n",
    "next_obs = None\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 2., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 2., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "0.10182011127471924\n"
     ]
    }
   ],
   "source": [
    "next_obs, reward, done, info = model.env.step([3])\n",
    "reward_input = np.array((obs.reshape((11, 11)), next_obs.reshape((11, 11)))).astype(np.float32)\n",
    "print(float(rm(np.expand_dims(reward_input, axis=0)).item()))\n",
    "obs = next_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = gym.make('EmptyMaze-10x10-FixedGoal-v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ve = DummyVecEnv([lambda: e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 11, 11)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = ve.reset()\n",
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]], dtype=uint8)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = ve.reset()\n",
    "next_obs = None\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 1, 11, 11]) torch.float32\n",
      "tensor([[[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "           [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "           [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "           [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "           [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "           [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "           [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "           [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "           [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "           [1., 0., 0., 0., 0., 0., 0., 0., 2., 3., 1.],\n",
      "           [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "           [1., 0., 2., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "           [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "           [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "           [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "           [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "           [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "           [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "           [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "           [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "           [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]]])\n",
      "0.1091046929359436\n"
     ]
    }
   ],
   "source": [
    "next_obs, reward, done, info = ve.step([3])\n",
    "reward_input = np.array((obs, next_obs)).astype(np.float32)\n",
    "print(float(rm(np.expand_dims(reward_input, axis=0)).item()))\n",
    "obs = next_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info[0]['terminal_observation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('EmptyMaze-10x10-TwoGoals-v3')\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm = RewardModel(env, 'cpu').to('cpu')\n",
    "rm.load_state_dict(th.load(f\"../reward-models/EmptyMaze-10x10-CoinFlipGoal-v3_ss-reward_model.pt\", map_location='cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CustomRewardSSWrapper(env, rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 1 1 1 1 1 1 1 1 1 1]\n",
      "  [1 3 0 0 0 0 0 0 0 0 1]\n",
      "  [1 0 0 0 0 0 0 0 0 0 1]\n",
      "  [1 0 0 0 0 2 0 0 0 0 1]\n",
      "  [1 0 0 0 0 0 0 0 0 0 1]\n",
      "  [1 0 0 0 0 0 0 0 0 0 1]\n",
      "  [1 0 0 0 0 0 0 0 0 0 1]\n",
      "  [1 0 0 0 0 0 0 0 0 0 1]\n",
      "  [1 0 0 0 0 0 0 0 0 0 1]\n",
      "  [1 0 0 0 0 0 0 0 0 3 1]\n",
      "  [1 1 1 1 1 1 1 1 1 1 1]]]\n",
      "[tensor([[-0.0313]], grad_fn=<MmBackward>)]\n"
     ]
    }
   ],
   "source": [
    "obs, reward, done, info = env.step([3])\n",
    "print(obs)\n",
    "print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 2., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00657362]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.0106836]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 2., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00962022]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 2., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 2., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00670287]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 2., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 2., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.01600172]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 2., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 2., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00382459]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 2., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00116345]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00619496]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 2., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.01091036]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 2., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[-0.00331333]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00368011]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00977446]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00450915]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00114229]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00330195]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00920045]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00920045]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00982593]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00730276]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00619496]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00368011]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00977446]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.0044475]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00252512]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00411028]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00064999]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[-0.00564986]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00607324]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00203048]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00338495]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00656891]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.01050441]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 2., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.0058921]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 2., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00567442]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00201876]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.003252]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 2., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00629511]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 2., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00555336]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.003252]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.003252]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.003252]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.003252]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.003252]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.003252]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.003252]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00559756]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00201876]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.003252]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 2., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00629511]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 2., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 2., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00755426]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 2., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 2., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00755426]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 2., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 2., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00755426]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 2., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 2., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00416097]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 2., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00454488]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00201876]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.003252]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.003252]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 2., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00629511]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 2., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00555336]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 2., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 2., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00566056]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 2., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.0059488]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00408962]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.0067555]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00543791]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.01050441]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00543791]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00995141]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00203048]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00995141]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 2., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[-0.0013182]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 2., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 2., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00635506]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 2., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 2., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00872785]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 2., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 2., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00601476]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 2., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 2., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.0083205]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 2., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 2., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00584872]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 2., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 2., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00526585]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 2., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 2., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.01112336]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 2., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 2., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00644271]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 2., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 2., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00945532]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 2., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 2., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00969617]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 2., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 2., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.01112336]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 2., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 2., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00377898]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 2., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 2., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00606245]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 2., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 2., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00492141]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 2., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 2., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00505602]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 2., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 2., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.00769863]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 2, 11, 11]) torch.float32\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 2., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0., 2., 0., 0., 0., 0., 3., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "[0.09285453]\n"
     ]
    }
   ],
   "source": [
    "obs = senv.reset()\n",
    "for i in range(200):\n",
    "    action, _states = model.predict(obs, deterministic=False)\n",
    "    next_obs, reward, done, info = senv.step(action)\n",
    "    print(reward)\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
