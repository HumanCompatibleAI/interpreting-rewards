# interpreting-rewards
Eric and Adam's repo for doing interpretability on reward models.
